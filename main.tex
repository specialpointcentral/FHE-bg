\documentclass[aspectratio=169]{beamer}

\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{pgfpages}
\usepackage{tikz}
\usetikzlibrary{arrows.meta,calc,decorations.pathmorphing}

\DeclareMathOperator{\Enc}{Enc}
\DeclareMathOperator{\Dec}{Dec}
\newcommand{\plaintext}[1]{\textcolor{orange!80!yellow}{#1}}
\newcommand{\ciphertext}[1]{\textcolor{teal!75!black}{#1}}
\newcommand{\seckey}[1]{\textcolor{violet!60!white}{#1}}

\setbeameroption{show notes on second screen=right}

\title{Background of Fully Homomorphic Encryption}
\subtitle{CKKS and TFHE}
\author{HU Qi\\PhD Student in HKU}
\institute{The University of Hong Kong}
\date{\today}

\begin{document}

\begin{frame}[plain]
  \titlepage
\end{frame}

\begin{frame}{1.1 Motivation and Definition of FHE}
  \begin{itemize}
    \item \textbf{Reality tension:} data must be ``used'' without ever being ``seen''.
    \begin{itemize}
      \item Cloud outsourcing: model inference, statistical analytics, search indexing.
      \item Regulatory pressure: GDPR, HIPAA, and cross-border data controls.
      \item Traditional encryption covers storage and transit, but requires decryption for computation.
    \end{itemize}
    \item \textbf{Privacy-computing goal:} make data usable while keeping it confidential.
    \begin{itemize}
      \item Servers only handle ciphertext yet complete the agreed computation.
      \item Clients decrypt and recover the same outcome as plaintext evaluation.
    \end{itemize}
    \item \textbf{FHE definition:} core property $\Dec(f(\Enc(x))) = f(x)$.
    \begin{itemize}
      \item Meaning: homomorphic $f$ on ciphertext, decrypt for the plaintext result.
    \end{itemize}
    \item \textbf{Typical applications:}
    \begin{itemize}
      \item Healthcare: encrypted imaging or genomics analysed in the cloud, hospitals decrypt locally.
      \item Finance: encrypted transactions scored for risk or collaborative anti-fraud.
      \item Privacy smart contracts: on-chain ciphertexts with off-chain/on-chain FHE execution.
    \end{itemize}
  \end{itemize}
  \note{Start with the question: why compute under encryption? Cloud inference, analytics, and risk scoring clash with GDPR, HIPAA, and cross-border rules that forbid revealing plaintext. Traditional encryption protects storage and transit yet forces decryption right before computation—the riskiest moment. Privacy computing keeps servers on ciphertext while clients decrypt to recover the same output; the identity $\Dec(f(\Enc(x))) = f(x)$ uses the same logical $f$, with ciphertexts processed through matching homomorphic operations. FHE keeps data encrypted end-to-end, removing the server-side decrypt-compute step and shrinking leakage on untrusted infrastructure. Applications span encrypted medical AI, financial risk scoring on ciphertexts, encrypted inputs to cloud models with local decryption, and privacy smart contracts.}
\end{frame}

\begin{frame}{1.2 Evolution of Fully Homomorphic Encryption}
  \begin{itemize}
    \item 2009: Gentry's breakthrough first-generation scheme based on ideal lattices.
    \item 2011--2014: Second generation (BGV, BFV) improves efficiency via leveled FHE and bootstrapping optimizations.
    \item 2016: CKKS introduces approximate arithmetic for real-number workloads such as machine learning inference.
    \item 2016+: TFHE enables fast gate-by-gate Boolean computation with rapid bootstrapping.
    \item Current landscape: hybrid approaches, GPU acceleration, and practical libraries (HElib, SEAL, Concrete, OpenFHE).
  \end{itemize}
  \note{Here I sketch the trajectory of FHE. After Gentry's 2009 construction, leveled schemes like BGV and BFV reduced overhead. CKKS later delivered approximate arithmetic suited for ML, while TFHE focused on fast Boolean gates with efficient bootstrapping. Today the ecosystem blends these ideas, pushing toward practical deployments with optimized libraries and hardware acceleration.}
\end{frame}

\section{Mathematical Foundations of FHE}

\begin{frame}{2. Mathematical Foundations Overview}
  \begin{itemize}
    \item Modular arithmetic and polynomial rings ($\mathbb{Z}_q$, $R_q$) as the container for ciphertext addition/multiplication.
    \item Batched (SIMD) encoding intuition: one encrypted polynomial carries many data slots.
    \item Hardness assumptions from LWE/RLWE tying noisy linear equations to ring-based constructions.
  \end{itemize}
  \note{Preview the three ingredients: the modular polynomial ring container, SIMD-style batching intuition, and the LWE/RLWE hardness assumptions that secure schemes.}
\end{frame}

\begin{frame}{2.1 Modular Arithmetic and Polynomial Rings}
  \begin{itemize}
    \item Modern FHE schemes encode ciphertexts as polynomials over rings to support both addition and multiplication (ring = additive group + multiplicative semigroup).
    \item Integer modular ring: $\mathbb{Z}_q = \{0,1,\dots,q-1\}$ with addition/multiplication taken mod $q$ (typically a large prime or an RNS prime chain).
    \item Polynomial ring: $R_q = \mathbb{Z}_q[x]/(x^N+1)$ with $N$ usually a power of two.
    \begin{itemize}
      \item Elements are polynomials of degree $< N$ with coefficients in $\mathbb{Z}_q$.
      \item Multiplication: convolve coefficients, then reduce by $(x^N+1)$ so $x^N \equiv -1$.
    \end{itemize}
  \end{itemize}
  \note{Explain that FHE ciphertexts need a structure supporting both addition and multiplication, so most schemes work in polynomial rings over modular integers. First define $\mathbb{Z}_q$ with mod-$q$ arithmetic (often using large primes or RNS chains). Then show how $R_q = \mathbb{Z}_q[x]/(x^N+1)$ (with $N$ as a power of two) contains polynomials of degree less than $N$, and multiplication is implemented via convolution followed by reduction modulo $x^N+1$, effectively forcing $x^N$ to behave like $-1$.}
\end{frame}

\begin{frame}{2.2 Intuition for Batched (SIMD) Encoding}
  \begin{itemize}
    \item Goal: start from a complex vector\\
      $$z = (z_1, z_2, \dots, z_{N/2}) \in \mathbb{C}^{N/2},$$
      encode it into the CKKS ring $R_q = \mathbb{Z}_q[x]/(x^N+1)$.
    \item Observation: when $N$ is a power of two, there is an approximate isomorphism\\
      $$R_q \otimes \mathbb{C} \cong \mathbb{C}^{N/2},$$
      so one ciphertext carries $N/2$ complex slots.
    \item Practical encoding: run the complex-domain inverse DFT (discrete Fourier transform) to map slots into polynomial coefficients\\
      $$m(x) = \mathrm{Inverse\text{-}DFT}(z),$$
      then scale and round to obtain an integer polynomial $\tilde{m}(x)$ before reducing modulo $q$, so $\tilde{m}(x) \bmod q \in \mathbb{Z}_q[x]$.
  \end{itemize}
  \note{Explain that batching in CKKS means taking a complex vector $z$ and embedding it into the polynomial ring. The key fact is the approximate isomorphism $R_q \otimes \mathbb{C} \cong \mathbb{C}^{N/2}$ when $N$ is a power of two; hence each ciphertext holds $N/2$ complex slots. Practically we run an inverse DFT on $z$ in the complex domain to produce $m(x)$, then scale and round to an integer polynomial $\tilde{m}(x)$ and reduce modulo $q$ so it lives in $\mathbb{Z}_q[x]$ before encryption.}
\end{frame}

\begin{frame}{2.3 LWE and RLWE}
  \begin{itemize}
    \item Motivation: Learning With Errors (LWE) and Ring-LWE (RLWE) provide computationally controllable, provably secure public-key and homomorphic encryption foundations.
    \item Core idea: add random noise to hide plaintexts while preserving ring/polynomial structure for computation, reducing security to GapSVP (quantum-resistant).
    \item LWE (vector form): samples $(A, b = A s + e \bmod q)$ where $A$ is random, $s$ secret, $e$ small noise.
    \item RLWE (polynomial form): samples $(a(x), b(x) = a(x) s(x) + e(x) \bmod q)$ over $R_q$.
    \item Transition: RLWE inherits LWE hardness while enabling structured polynomials that FHE schemes rely on.
  \end{itemize}
  \note{Introduce why we need LWE/RLWE: they add controlled random noise to hide plaintexts while preserving the ring/polynomial structure needed for computation, with security reducible to GapSVP even against quantum adversaries. Briefly define LWE via noisy linear equations $b = As + e \pmod{q}$ and RLWE via polynomial samples $b(x) = a(x)s(x)+e(x) \pmod{q}$ inside $R_q$. Emphasize that RLWE inherits LWE hardness yet aligns with the polynomial ring container used in FHE, enabling efficient and analyzable homomorphic schemes.}
\end{frame}

\begin{frame}{2.4 LWE: Key Generation, Encryption, Decryption}
  \begin{description}
    \item[Key generation] Sample $\seckey{s} \leftarrow \mathbb{Z}_q^n$, noise $e \leftarrow \mathbb{Z}_q^n$, and public randomness $A \leftarrow \mathbb{Z}_q^{n \times n}$. Set
    $$
      b = A \seckey{s} + e \pmod{q}.
    $$
    Publish $(A, b)$; keep $\seckey{s}$ secret.
    \item[Encryption of $\plaintext{m} \in \{0,1\}$] Pick a small random vector $r$, then compute
    \[
      c_0 = A^\top r,\qquad
      c_1 = b^\top r + \Delta \plaintext{m},
    \]
    forming ciphertext $\boxed{c = (c_0, c_1)}$,
    where the scaling constant is $\Delta = q/2$ for a binary alphabet (or $q/L$ for $L$ equally spaced levels). As a quick sanity check, let $r = \mathbf{1}$ so $c_0$ simply sums the columns of $A$.
    \item[Decryption with $\seckey{s}$] Evaluate
    \[
      c_1 - c_0^\top \seckey{s} = e^\top r + \Delta \plaintext{m}.
    \]
    Because $e^\top r$ is tiny, we recover the message by normalizing and rounding:
    $$
      \widehat{m} = \operatorname{round}\!\left(\frac{c_1 - c_0^\top \seckey{s}}{\Delta}\right),
    $$
    which snaps back to the original $\plaintext{m}$.
  \end{description}
  \note{“Here is the full LWE workflow. First sample the bright-violet secret key $\seckey{s}$ along with noise $e$ and public matrix $A$, then publish the vector $b = A\seckey{s} + e \bmod q$ as part of the public key. The bright-orange $\plaintext{m}$ is the plaintext bit we encrypt. Pick a short random vector $r$—in the simplest thought experiment let $r = \mathbf{1}$ so $c_0 = A^\top r$ just sums the columns—and compute $c_0$ plus $c_1 = b^\top r + \Delta \plaintext{m}$ where $\Delta = q/2$ because the message alphabet has two symbols (if there were $L$ symbols we’d set $\Delta = q/L$). Decryption is $c_1 - c_0^\top \seckey{s}$: the cross terms cancel, leaving $e^\top r + \Delta \plaintext{m}$. Since the error is tiny, divide by $\Delta$ and round to recover $\plaintext{m}$. This emphasizes how the noisy value sits near a multiple of $\Delta$ and snaps back to the intended plaintext.”}
\end{frame}

\begin{frame}{2.5 RLWE: $b(x) = a(x)s(x) + e(x) \pmod{q}$}
  \begin{description}
    \item[Ring setting] Work in $R_q = \mathbb{Z}_q[x]/(x^N+1)$ with secret $\seckey{s(x)}$ and small error $e(x)$ drawn from a narrow distribution on $R_q$.
    \item[Key generation] Sample public $a(x) \leftarrow R_q$, draw $e(x)$, and set
    \[
      b(x) = a(x)\seckey{s(x)} + e(x) \pmod{q}.
    \]
    Publish $(a(x), b(x))$, keep $\seckey{s(x)}$ secret.
    \item[Encryption of plaintext $\plaintext{m(x)} \in R_q$] Pick a small, sparse $r(x)$ (conceptually set $r(x)=1$ to sanity-check the formulas) and output
    \[
      c_0(x) = a(x) r(x), \qquad
      c_1(x) = b(x) r(x) + \Delta \, \plaintext{m(x)},
    \]
    with $\Delta = q/t$ for $t$ plaintext slots (e.g., $t=2$ for binary messages), then package $\boxed{c(x) = (c_0(x), c_1(x))}$.
    \item[Decryption] Compute
    \[
      c_1(x) - c_0(x) \seckey{s(x)} = \Delta \, \plaintext{m(x)} + \widetilde{e}(x),
    \]
    divide by $\Delta$, and round coefficient-wise to strip the small noise.
  \end{description}
  \note{“RLWE lifts everything into the polynomial ring $R_q = \mathbb{Z}_q[x]/(x^N+1)$. The bright-violet $\seckey{s(x)}$ is now a polynomial secret with small coefficients; noise polynomials come from discrete Gaussian or bounded distributions on the ring. Key generation samples a public $a(x)$, draws $e(x)$, and publishes $b(x) = a(x)\seckey{s(x)} + e(x) \bmod q$. To encrypt a bright-orange $\plaintext{m(x)}$ we pick a fresh small $r(x)$—even imagining $r(x)=1$ for intuition—and set $c_0 = a r$ and $c_1 = b r + \Delta \plaintext{m(x)}$ with $\Delta = q/t$ depending on how many plaintext slots we encode. Decryption subtracts $c_0 \seckey{s(x)}$ from $c_1$: the $a \seckey{s}$ terms cancel, leaving $\Delta \plaintext{m(x)}$ plus tiny noise. Dividing by $\Delta$ and rounding coefficient-wise recovers $\plaintext{m(x)}$.}
\end{frame}

\section{CKKS}

\begin{frame}{3. CKKS Overview}
  \begin{itemize}
    \item Approximate-number FHE supporting packed real/complex vectors (SIMD-style).
    \item Workflow: scale plaintexts by a large $\Delta$, encode integers into RLWE polynomials, then encrypt.
    \item Homomorphic addition is cheap (same scale); multiplication requires relinearization + rescale to control growth.
    \item Resulting ciphertexts keep bounded precision error, making CKKS practical for ML inference and analytics.
  \end{itemize}
  \note{“This section introduces CKKS, currently the most widely deployed homomorphic encryption scheme for real and complex vectors. It lets us perform additions and multiplications directly on encrypted data while keeping the final precision error under control. The core trick is to multiply real numbers by a large scaling factor $\Delta$, convert them to integers, and encode those integers into RLWE polynomials before encrypting. Additions preserve the scale so they are almost free. Multiplications, however, inflate the scale and ciphertext size, so we fix things with two steps: relinearization to bring the ciphertext back to its normal dimension, and rescaling to divide away the oversized scale so precision does not keep degrading.”}
\end{frame}

\begin{frame}{3.1 CKKS Encoding and Scaling}
  \begin{description}
    \item[Goal] Encode a real vector $(z_1, z_2, \dots, z_k)$ into the polynomial ring $R_q = \mathbb{Z}_q[x]/(x^N + 1)$ so CKKS can process it homomorphically.
    \item[Scaling] Multiply each real by a large $\Delta$ so fractional parts become big integers:
    $$
      \widetilde{m} = \Delta \cdot m,
    $$
    because all CKKS arithmetic happens modulo $q$.
    \item[Encoding] (Same SIMD trick as Section 2.2) leverage $R_q \otimes \mathbb{C} \cong \mathbb{C}^{N/2}$ to pack the scaled vector into one polynomial—each slot stores one entry, enabling parallel processing.
    \item[Decoding] After decryption, recover the integer vector and reverse the scaling:
    $$
      m \approx \frac{1}{\Delta} \cdot \widetilde{m},
    $$
    yielding the original reals up to a controllable approximation error.
  \end{description}
  \note{“To let CKKS encrypt and compute on reals we first have to move them into the integer polynomial ring. Two steps make this work: scaling and encoding. We multiply each real number by a large $\Delta$, turning fractional values into big integers, because all homomorphic operations happen modulo $q$ and floats are not allowed. Then we rely on the ring decomposition $R_q \otimes \mathbb{C} \cong \mathbb{C}^{N/2}$ to map an entire vector into a single polynomial—each coefficient, or slot, holds one value, exactly like the SIMD batching we introduced earlier. This is why one CKKS ciphertext can process many numbers in parallel. During decryption we reverse the process: convert the polynomial back to its integer vector and divide by $\Delta$ to get an approximation of the original reals. Hence CKKS is an approximate FHE scheme with controllable precision error.”}
\end{frame}

\begin{frame}{3.2 CKKS Encryption and Decryption}
  \begin{description}
    \item[Plaintext prep] Before encryption, scale by $\Delta$ and encode the real vector into an integer polynomial $\plaintext{m(x)}$ (Section~2.2 + 3.1).
    \item[Key generation] Identical to RLWE (Section~2.5): pick small $\seckey{s(x)}$, sample random $a(x)$ and noise $e(x)$, then publish
    $$
      b(x) = a(x) \seckey{s(x)} + e(x) \pmod{q}.
    $$
    \item[Encryption] Form ciphertext $c(x) = \bigl(c_0(x), c_1(x)\bigr)$ via
    \[
      c_0(x) = a(x) r(x), \qquad
      c_1(x) = b(x) r(x) + \Delta \, \plaintext{m(x)},
    \]
    where $r(x)$ is a fresh small polynomial.
    \item[Decryption] Subtract and divide by the recorded scale:
    \[
      c_1(x) - c_0(x)\seckey{s(x)} = \Delta \, \plaintext{m(x)} + \widetilde{e}(x)
    \]
    and compute $m(x) \approx \frac{1}{\Delta}\bigl(c_1 - c_0 \seckey{s}\bigr)$.
    \item[Scale tracking] CKKS ciphertexts explicitly store the current $\Delta$: here it records fixed-point precision (unlike RLWE’s $\Delta = q/t$ embedding) and is updated after every homomorphic operation.
  \end{description}
  \note{“This slide revisits encryption and decryption in CKKS. The workflow is literally the same as the RLWE recipe from Section 2.5—the only twist is that CKKS prepares the plaintext by scaling it with $\Delta$ and encoding it into an integer polynomial before we ever touch the public key. Key generation samples a small-coefficient secret $\seckey{s(x)}$, random $a(x)$, and noise $e(x)$ to produce $b(x) = a(x)\seckey{s(x)} + e(x) \bmod q$. Encryption outputs $c_0 = a r$ and $c_1 = b r + \Delta \plaintext{m(x)}$ for a fresh small $r(x)$. Decryption subtracts $c_0 \seckey{s}$ from $c_1$ so the RLWE terms cancel, leaving $\Delta \plaintext{m(x)}$ plus tiny noise; dividing by the stored $\Delta$ recovers the approximate real vector. Crucially, CKKS’s $\Delta$ represents the fixed-point scale for numerical precision, whereas RLWE’s $\Delta = q/t$ simply maps a plaintext modulus into $q$. That’s why every CKKS ciphertext carries its current scale, which must be updated after additions, multiplications, and rescaling to keep precision under control.”}
\end{frame}

\begin{frame}{3.3 CKKS Rescaling and Scale Management}
  \begin{description}
    \item[Why rescale?] Ciphertexts encode scaled approximations $\plaintext{m}\cdot\Delta$. A homomorphic multiplication inflates the scale to $\Delta^2$:
    $$
      (\Delta \cdot m_0) \cdot (\Delta \cdot m_1) = \Delta^2 \cdot (m_0 m_1),
    $$
    so repeated multiplications would push the scale (and noise) out of range.
    \item[Operation] With ciphertext $c = (c_0, c_1) \in R_Q$ at scale $\Delta$ over modulus chain $Q = q_0 q_1 \dots q_L$,
    $$
      c' = \operatorname{Rescale}(c) = \left\lfloor \frac{c}{q_L} \right\rceil \bmod \frac{Q}{q_L},
    $$
    consuming the bottom modulus.
    \item[Effect] New parameters become
    $$
      \Delta' = \frac{\Delta}{q_L}, \qquad Q' = \frac{Q}{q_L},
    $$
    keeping the fixed-point scale within target bounds at the cost of one level.
  \end{description}
  \note{“Rescaling is CKKS’s way of taming the scale explosion caused by multiplication. Remember that ciphertexts store scaled approximations $\plaintext{m}\cdot\Delta$; multiplying two of them yields $(m_1 \Delta)(m_2 \Delta) = (m_1 m_2)\Delta^2$, just like fixed-point multiplication shifting the decimal twice. If we do nothing, the scale and noise blow up. The remedy is the rescale step: divide the ciphertext by the lowest modulus $q_L$ in the chain and round, producing $c' = \lfloor c / q_L \rceil \bmod (Q/q_L)$. This simultaneously reduces the modulus to $Q' = Q / q_L$ and shrinks the scale to $\Delta' = \Delta / q_L$, pulling the fixed-point representation back into the desired range. Every rescale consumes a level, so we plan circuits so there’s enough modulus budget for all future multiplications.”}
\end{frame}

\begin{frame}{3.4 CKKS Homomorphic Addition}
  \begin{description}
    \item[Component-wise sum] Ciphertexts live as pairs $(c_0, c_1)$, so addition is
    $$
      (c_0, c_1) + (c'_0, c'_1) = (c_0 + c'_0,\; c_1 + c'_1),
    $$
    preserving the decrypted quantity $c_1 - c_0 \seckey{s}$ slot-wise.
    \item[Scale alignment] Addition requires both operands to share the same stored scale $\Delta$; if not, rescale one ciphertext first (Section~3.3) to keep fixed-point alignment.
    \item[Effect on noise] The scale remains unchanged and noise growth is negligible, so this is CKKS’s cheapest, most stable homomorphic primitive.
  \end{description}
  \note{“Homomorphic addition in CKKS is the simplest operation. Each ciphertext is a pair $(c_0, c_1)$, so we just add the two components: $(c_0, c_1) + (c'_0, c'_1) = (c_0 + c'_0,\; c_1 + c'_1)$. Because the decrypted value is $c_1 - c_0 s$, the slot-wise sum of plaintext approximations pops out immediately. The only caveat is that both operands must carry the same scale $\Delta$—if they differ, we rescale one ciphertext as described on slide 3.3 so the fixed-point alignment makes sense. Addition doesn’t change $\Delta$ and only nudges the noise a tiny amount, so it is extremely cheap and stable compared with homomorphic multiplication. This contrast sets up the next slide where multiplication inflates scale and ciphertext size.”}
\end{frame}

\begin{frame}{3.5 CKKS Homomorphic Multiplication and Relinearization}
  \begin{description}
    \item[Multiplication result] Each ciphertext decrypts as $c_1 - c_0 \seckey{s} \approx \Delta \cdot \plaintext{m}$. Multiplying two ciphertexts therefore expands
    $$
      (c_1 - c_0 \seckey{s}) (c'_1 - c'_0 \seckey{s}) =
      d_0 + d_1 \seckey{s} + d_2 \seckey{s}^2,
    $$
    where
    \[
      d_0 = c_1 c'_1,\quad
      d_1 = -(c_1 c'_0 + c_0 c'_1),\quad
      d_2 = c_0 c'_0.
    \]
    \item[Why relinearize] The appearance of the $d_2 \seckey{s}^2$ term enlarges the ciphertext (now $(d_0, d_1, d_2)$) and would require the secret key squared to decrypt, increasing storage and computation.
    \item[Relinearization] Apply the evaluation key $\mathrm{EvalKey}(s^2)$ to fold the $d_2 \seckey{s}^2$ contribution back into the two-term format:
    \[
      (c_0, c_1) \times (c'_0, c'_1)
      \xrightarrow{\text{multiply}}
      (d_0, d_1, d_2)
      \xrightarrow[\text{remove } d_2 (s^2)]{\text{relinearize}}
      (e_0, e_1).
    \]
    \item[Reference] CKKS paper (Cheon--Kim--Kim--Song, ASIACRYPT~2017).\footnote{Cheon, Kim, Kim, Song, “Homomorphic Encryption for Arithmetic of Approximate Numbers,” ASIACRYPT 2017.}
  \end{description}
  \note{“Decrypting a CKKS ciphertext uses $c_1 - c_0 s \approx \Delta \cdot m$. When we multiply two ciphertexts we multiply those decrypted forms, so $(c_1 - c_0 s)(c'_1 - c'_0 s)$ expands to $d_0 + d_1 s + d_2 s^2$ with $d_0 = c_1 c'_1$, $d_1 = -(c_1 c'_0 + c_0 c'_1)$, and $d_2 = c_0 c'_0$. That third term corresponds to an $s^2$ component, so the ciphertext effectively has three pieces $(d_0, d_1, d_2)$. If we let those accumulate, ciphertext size and key-switching cost skyrocket because the secret key powers keep growing. Relinearization uses a precomputed evaluation key tied to $s^2$ to absorb $d_2$ back into the first two terms, producing a standard two-component ciphertext $(e_0, e_1)$ that decrypts with just $s$. We always relinearize immediately after multiplication before moving on to rescaling. The full construction lives in the original CKKS paper by Cheon, Kim, Kim, and Song (Asiacrypt 2017) if you want the formal treatment.”}
\end{frame}

\section{TFHE}

\begin{frame}{4. TFHE Overview}
  \begin{description}
    \item[Computation model] TFHE operates on encrypted bits; each Boolean value is packed into a (T)LWE sample, unlike CKKS’s approximate real vectors.
    \item[Encryption layer] LWE-style keys/encapsulation; with $r = \mathbf{1}$ and $m \in \{0,1\}$:
    $$c = (c_0, c_1) = \bigl(A,\, A\seckey{s} + \mu \plaintext{m} + e\bigr),$$
    where $\mu$ (typically $q/2$) plays the role of the LWE scaling factor $\Delta$.
    \item[Logic gates] Supports homomorphic AND/XOR/NOT primitives, making it ideal for comparisons, branching, verification, and encrypted control flow.
    \item[Bootstrapping] Every gate invocation bootstraps away noise, allowing arbitrarily deep Boolean circuits with stable precision.
    \item[Contrast to CKKS] CKKS excels at numeric workloads but struggles with exact branching or comparisons; TFHE provides the complementary bit-level toolkit.
  \end{description}
  \note{“Now we pivot to TFHE, which follows a completely different computation model from CKKS. CKKS encrypts approximate real vectors, whereas TFHE encrypts individual bits—each one is a TLWE/LWE sample. The scheme’s core idea is to evaluate Boolean gates such as AND, XOR, and NOT directly on ciphertexts, making it the go-to option for comparisons, conditional checks, verification protocols, and encrypted code execution. CKKS is ill-suited for these bit-level tasks. TFHE reuses the LWE-style key generation and encryption workflow; for intuition we can set $r = \mathbf{1}$ so the ciphertext looks like $(c_0, c_1) = (A, A \seckey{s} + \mu m + e)$ just like in Section 2.4, with $m \in \{0,1\}$ and $\mu$ playing the role of the earlier scaling factor $\Delta$. The killer feature is bootstrapping: every gate refreshes the noise budget, so we can evaluate arbitrarily deep logic circuits without the noise blow-up that plagues other schemes. While CKKS also has bootstrapping variants, their noise-refresh performance lags far behind TFHE’s per-gate bootstrap. This bit-level capability fills the gap left by CKKS’s numeric focus.”}
\end{frame}

\begin{frame}{4.1 TFHE Gate Operations}
  \begin{description}
    \item[Ciphertext form] Encrypt each bit $m \in \{0,1\}$ as $c = (A, c_1)$ with $c_1 = A\seckey{s} + \mu m + e$.
    \item[NOT gate] Flip the phase to encode $1 - m$; equivalently $c_1' = A\seckey{s} + \mu (1 - m) + e$:
    $$\text{NOT}(c) = \bigl(-A,\; \mu - c_1\bigr) \bmod q.$$
    \item[XOR gate] Homomorphic addition implements XOR:
    $$\text{XOR}(c_0, c_1) = c_0 + c_1 \pmod{q}.$$
    \item[AND challenge] Multiplicative gates inflate scale/noise since
    $$
      (m_0 \mu)(m_1 \mu) = (m_0 m_1) \mu^2,
    $$
    so TFHE uses bootstrapping to refresh ciphertexts after AND/NAND.
  \end{description}
  \note{“Each TFHE ciphertext encrypts a bit $m \in \{0,1\}$ as $(A, c_1)$ with $c_1 = A s + \mu m + e$. For NOT we flip the phase: $(1 - m)\mu = \mu - m\mu$, so the refreshed component becomes $c_1' = A s + \mu (1 - m) + e$ and the ciphertext is $( -A,\; \mu - c_1 ) \bmod q$. XOR is simply ciphertext addition because the arithmetic is linear, so $\text{XOR}(c, c') = c + c' \pmod{q}$. AND and NAND are harder: multiplying ciphertexts corresponds to $(\mu m_0)(\mu m_1) = \mu^2 m_0 m_1$, which squares the scale and noise. TFHE combats that by bootstrapping right after multiplicative gates, keeping the noise budget low enough for deep Boolean circuits.”}
\end{frame}

\begin{frame}{4.2 TFHE Programmable Bootstrapping (PBS)}
  \begin{itemize}
    \item Outline how PBS refreshes noise while applying an arbitrary function encoded as a lookup table.
    \item Note typical use cases: non-linear activations, comparison operators, and logic gates.
  \end{itemize}
  \note{Will later include step-by-step PBS equations, bootstrapping key structure, and runtime considerations.}
\end{frame}

\end{document}
